{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "toc_visible": true,
      "gpuType": "T4",
      "authorship_tag": "ABX9TyMtHoVA3zi0NEJ1tLm8cUiA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/krodri95/MNIST-Classifier/blob/main/mnist.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mnWOi4k6Ik6w",
        "outputId": "ee09bb38-aae1-477c-853b-e4c4793ec19d"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "import torch.optim as optim\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "from torchvision.transforms import Resize\n",
        "\n",
        "from PIL import Image\n",
        "from tqdm import tqdm\n",
        "import time\n",
        "import numpy as np\n",
        "\n",
        "from google.colab import files\n",
        "import matplotlib.pyplot as plt\n",
        "import cv2\n",
        "from google.colab.patches import cv2_imshow\n",
        "\n",
        "print(torch.cuda.is_available())\n",
        "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def autopad(k, p=None):  # kernel, padding\n",
        "    # Pad to 'same'\n",
        "    if p is None:\n",
        "        p = k // 2 if isinstance(k, int) else [x // 2 for x in k]  # auto-pad\n",
        "    return p\n",
        "\n",
        "\n",
        "class Conv(nn.Module):\n",
        "    # Standard convolution\n",
        "    def __init__(self, c1, c2, k=1, s=1, p=None, g=1, act=True):  # ch_in, ch_out, kernel, stride, padding, groups\n",
        "        super().__init__()\n",
        "\n",
        "        self.conv = nn.Conv2d(c1, c2, k, s, autopad(k, p), groups=g, bias=False)\n",
        "        self.bn = nn.BatchNorm2d(c2)\n",
        "        self.act = nn.ReLU() if act is True else (act if isinstance(act, nn.Module) else nn.Identity())\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.act(self.bn(self.conv(x)))\n",
        "\n",
        "\n",
        "class Model(nn.Module):\n",
        "    def __init__(self, nc=None):\n",
        "        super().__init__()\n",
        "        self.conv1 = Conv(1, 32, 3)\n",
        "        self.pool1 = nn.MaxPool2d(2, 2)\n",
        "        self.conv2 = Conv(32, 64, 3)\n",
        "        self.pool2 = nn.MaxPool2d(2, 2)\n",
        "        self.conv3 = Conv(64, 128, 3)\n",
        "        self.pool3 = nn.MaxPool2d(2, 2)\n",
        "        self.flat =  nn.Flatten()\n",
        "        self.fc1 = nn.Linear(128 * 6 * 6, 256)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.drop = nn.Dropout(p=0.4)\n",
        "        self.fc2 = nn.Linear(256*1*1, nc)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.pool1(self.conv1(x))\n",
        "        x = self.pool2(self.conv2(x))\n",
        "        x = self.pool3(self.conv3(x))\n",
        "        x = self.flat(x) # flatten all dimensions except batch\n",
        "        x = self.drop(self.relu(self.fc1(x)))\n",
        "        x = self.fc2(x)\n",
        "        return x"
      ],
      "metadata": {
        "id": "jZZYozrPKA1Z"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class RGB2BGR(object):\n",
        "    \"\"\"Convert RGB image to BGR image\"\"\"\n",
        "\n",
        "    def __call__(self, img):\n",
        "\n",
        "        data = np.array(img)\n",
        "        print(data.shape)\n",
        "        red, green, blue = data.T\n",
        "        data = np.array([blue, green, red])\n",
        "        data = data.transpose()\n",
        "        img = Image.fromarray(data)\n",
        "        return img"
      ],
      "metadata": {
        "id": "BCkmtLSpPFgU"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "transform = transforms.Compose([Resize((50, 50), Image.BILINEAR),\n",
        "                                #RGB2BGR(),\n",
        "                                transforms.ToTensor()])\n",
        "\n",
        "trainset = datasets.MNIST(\"\", train=True, download=True, transform = transform)\n",
        "trainloader = torch.utils.data.DataLoader(trainset, batch_size=8, shuffle=True)\n",
        "\n",
        "testset = datasets.MNIST(\"\", train=False, download=True, transform = transform)\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=8, shuffle=True)\n",
        "\n",
        "# Model\n",
        "model = Model(nc=10).to(device)  # create"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f5rBwPujQkPZ",
        "outputId": "8362a003-4655-4d82-e9cc-190e3f77015e"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to MNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 9912422/9912422 [00:00<00:00, 130803341.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/raw/train-images-idx3-ubyte.gz to MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to MNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 28881/28881 [00:00<00:00, 109229660.80it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/raw/train-labels-idx1-ubyte.gz to MNIST/raw\n",
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to MNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1648877/1648877 [00:00<00:00, 41703448.59it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/raw/t10k-images-idx3-ubyte.gz to MNIST/raw\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4542/4542 [00:00<00:00, 5455477.88it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting MNIST/raw/t10k-labels-idx1-ubyte.gz to MNIST/raw\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 1\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Start training\n",
        "t0 = time.time()\n",
        "\n",
        "nb = len(trainloader)  # number of batches\n",
        "running_loss = 0.0\n",
        "\n",
        "for epoch in range(epochs):  # loop over the dataset multiple times\n",
        "\n",
        "    model.train()\n",
        "    pbar = enumerate(trainloader)\n",
        "    print(('\\n' + '%10s' * 2) % ('Epoch', 'mloss'))\n",
        "    pbar = tqdm(pbar, total=nb, bar_format='{l_bar}{bar:10}{r_bar}{bar:-10b}')  # progress bar\n",
        "    running_loss = 0.0\n",
        "\n",
        "    for i, data in pbar:\n",
        "        # get the inputs; data is a list of [inputs, labels]\n",
        "        inputs, labels = data\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "\n",
        "        # zero the parameter gradients\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        # forward + backward + optimize\n",
        "        outputs = model(inputs)\n",
        "        loss = criterion(outputs, labels)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        # print statistics\n",
        "        running_loss += loss.item()\n",
        "\n",
        "        pbar.set_description(('%10s' * 2) % (f'{epoch}/{epochs - 1}', f'{running_loss / (i+1):.3f}'))\n",
        "\n",
        "\n",
        "    correct = 0\n",
        "    total = 0\n",
        "    # since we're not training, we don't need to calculate the gradients for our outputs\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        for data in testloader:\n",
        "            images, labels = data\n",
        "            images = images.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            # calculate outputs by running images through the network\n",
        "            outputs = model(images)\n",
        "            # the class with the highest energy is what we choose as prediction\n",
        "            _, predicted = torch.max(outputs.data, 1)\n",
        "            total += labels.size(0)\n",
        "            correct += (predicted == labels).sum().item()\n",
        "\n",
        "    print(('%20s') % (f'Accuracy : {100 * correct / total:.3f} %'))\n",
        "\n",
        "\n",
        "print(f'\\n{epochs} epochs completed in {(time.time() - t0) / 3600:.3f} hours.')\n",
        "\n",
        "# again no gradients needed\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R58E--D7MpCG",
        "outputId": "34bbb4b7-e865-4c06-98ec-d38a7c77808d"
      },
      "execution_count": 81,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "     Epoch     mloss\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "       0/0     0.017: 100%|██████████| 7500/7500 [01:00<00:00, 124.76it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " Accuracy : 99.110 %\n",
            "\n",
            "1 epochs completed in 0.017 hours.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#f = files.upload()\n",
        "img = cv2.imread('firstTest.png')\n",
        "img = cv2.resize(img, (50,50))\n",
        "img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
        "img = 255 - img #invert image\n",
        "cv2_imshow(img)\n",
        "\n",
        "img = torch.from_numpy(np.array(img/255)).float().to(device)\n",
        "outputs = model(img.view(1,1,50,50))\n",
        "\n",
        "# the class with the highest energy is what we choose as prediction\n",
        "_, predicted = torch.max(outputs, 1)\n",
        "\n",
        "print('Predicted Class: ', int(predicted))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 84
        },
        "outputId": "1c60622b-4fef-4cbc-9d97-772676020598",
        "id": "D-d5mDSfkk5E"
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<PIL.Image.Image image mode=L size=50x50>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAADIAAAAyCAAAAAA7VNdtAAAB+ElEQVR4nO2UPUhbURiG3+TeEI3aQjK4lYIFxV8KUaoUmkIjpf6BOIoOInaroHRQcahY6OJgaV1aqFN2QVA6dLGUiggKKjgJ6qAGFX/Q3uTmdTixuT/mntxNxHc65+N7zvudc75zgLsjjzWg+l/XAkB8bkPPbYm2pX0KabH8XACl+5gZfSuQE4G+BI2aDdnqtmqBFh1FJURE5G2NN0ajY5pgWp2RsE5SGxK7/pIkSf575VibZ5pM9HrFxPtJeJ5XO9qo9ZGy/xOlYY0kOeOV7MeoxyskyYgLBIW7JBlzg+AtSf62BB0LVVY1Vw7Ao1+XN7mo2fIfvntRL27oQoZ4yttKAaA5mA6kfsqqKTszt1lqTJEhwyZgsbPUdkC2wnZoaKp404HMAkDRurGq1WJ7hr1PfU8UAJUjFQCAtfbNHHyE/IOi+xOjLtryTfpVP80dQcc5SXLZ54IpmddJ8r300zDIt0KSe0F5ZkadJJnqdoOoSyQ5ZYqZTjDQ0l9u3mtyUrLmAnn5p9IUqrO7GCW+vvhAKBMKTTsjYV3c3clIjQoA3qrhI5LkZ1Oa8cg9P7rSIy32F0BFTx4AgC2zWW0efDywfuQk9a95WQkABd+TViL1wQkAoL7cMhOHTX4JAvifjZ9e519MPA/YEm7suGB7ejC/LXW4123RFVryYfVly+mpAAAAAElFTkSuQmCC\n"
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted Class:  3\n"
          ]
        }
      ]
    }
  ]
}